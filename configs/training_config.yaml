# Andromeda2 Training Configuration
# Hierarchical RL training setup for Rocket League agent

# Environment Configuration
environment:
  type: "1v1" # Environment type: "1v1", "2v2", "3v3", "training"
  num_envs: 16 # Number of parallel environments
  hierarchical: true # Use hierarchical RL wrapper
  tick_skip: 8 # Number of ticks to skip per step
  game_speed: 100 # Game speed multiplier
  spawn_opponents: true # Whether to spawn opponents
  auto_detect_demos: true # Auto-detect demolitions

  # Environment-specific settings
  training_type: "basic" # For training env: "basic", "aerial", "dribbling", "goalkeeping"

  # Vectorized environment settings
  async_env: false # Use asynchronous vectorized environment
  timeout: 60.0 # Timeout for environment operations
  shared_memory: true # Use shared memory for observations

# Agent Configuration
agent:
  observation_size: 107 # Size of AdvancedObs output
  action_size: 8 # Standard Rocket League action space
  goal_vector_dim: 12 # Dimension of goal vectors
  planner_update_freq: 8 # How often planner updates (in steps)
  goal_vector_scaling: 1.0 # Scaling factor for goal vectors
  training_mode: "hierarchical" # "hierarchical", "planner_only", "controller_only"
  use_memory_replay: false # Use memory replay for planner
  controller_type: "basic" # "basic", "adaptive", "ensemble"

# Planner Configuration (Official xLSTM)
planner:
  hidden_size: 512 # Hidden layer size for xLSTM blocks
  num_layers: 3 # Number of xLSTM layers
  slstm_at_layer: [0, 2] # Layer indices for sLSTM blocks
  mlstm_at_layer: [1] # Layer indices for mLSTM blocks
  dropout: 0.1 # Dropout probability
  embedding_dim: null # Embedding dimension (null = same as hidden_size)
  add_post_blocks_norm: true # Add normalization after blocks
  bias: false # Use bias in linear layers
  context_length: 2048 # Maximum context length for memory
  tie_weights: false # Tie input/output embeddings
  slstm_hidden_size_factor: 1.0 # Factor for sLSTM hidden size
  mlstm_memory_dim_factor: 1.0 # Factor for mLSTM memory dimension
  mlstm_num_heads: 4 # Number of heads for mLSTM attention

# Controller Configuration (MLP)
controller:
  hidden_sizes: [512, 512, 256, 128] # Hidden layer sizes
  dropout: 0.1 # Dropout probability
  activation: "relu" # Activation function: "relu", "gelu", "swish"
  use_batch_norm: true # Use batch normalization
  use_attention: false # Use attention mechanism
  use_goal_conditioning: "concat" # Goal conditioning: "concat", "film", "cross_attention"

# Training Configuration
training:
  # PPO Parameters
  learning_rate: 0.0003 # Base learning rate
  gamma: 0.99 # Discount factor
  gae_lambda: 0.95 # GAE lambda parameter
  clip_range: 0.2 # PPO clipping range
  entropy_coef: 0.01 # Entropy coefficient
  value_loss_coef: 0.5 # Value loss coefficient
  max_grad_norm: 0.5 # Maximum gradient norm for clipping

  # Training Schedule
  epochs_per_update: 10 # Number of epochs per PPO update
  batch_size: 64 # Batch size for training
  n_steps: 2048 # Number of steps per rollout
  total_timesteps: 10000000 # Total training timesteps

  # Hierarchical-specific
  planner_lr_multiplier: 0.5 # Learning rate multiplier for planner
  controller_lr_multiplier: 1.0 # Learning rate multiplier for controller
  separate_optimizers: true # Use separate optimizers for planner/controller
  normalize_advantages: true # Normalize advantages
  normalize_intrinsic_rewards: true # Normalize intrinsic rewards
  target_kl: 0.02 # Target KL divergence for early stopping

# Intrinsic Reward Configuration
intrinsic_rewards:
  # Weights for intrinsic reward components
  car_velocity: 1.0 # Weight for car velocity alignment
  ball_velocity: 1.0 # Weight for ball velocity alignment
  car_to_ball_pos: 1.0 # Weight for car-to-ball position alignment
  ball_to_goal_pos: 1.0 # Weight for ball-to-goal position alignment

# Logging and Evaluation
logging:
  log_interval: 1 # Log training stats every N updates
  save_frequency: 1000 # Save model every N updates
  eval_freq: 100 # Evaluate every N updates
  n_eval_episodes: 5 # Number of evaluation episodes

  # External logging
  use_wandb: true # Use Weights & Biases
  use_tensorboard: true # Use TensorBoard
  wandb_project: "andromeda2" # W&B project name
  wandb_entity: null # W&B entity (null = default)

  # Directories
  log_dir: "./logs" # Log directory
  checkpoint_dir: "./checkpoints" # Checkpoint directory

  # Metrics
  window_size: 100 # Window size for moving averages
  plot_frequency: 1000 # Generate plots every N updates

# Hardware Configuration
hardware:
  device: "auto" # Device: "auto", "cpu", "cuda", "cuda:0"
  num_workers: null # Number of worker processes (null = auto)
  pin_memory: true # Pin memory for DataLoader
  non_blocking: true # Non-blocking transfers

# Optimization
optimization:
  # Learning rate scheduling
  lr_schedule: "constant" # "constant", "linear", "cosine"
  lr_decay_steps: null # Steps for learning rate decay
  warmup_steps: 0 # Number of warmup steps

  # Gradient optimization
  grad_accumulation_steps: 1 # Gradient accumulation steps
  weight_decay: 0.0 # Weight decay
  adam_eps: 1e-5 # Adam epsilon

  # Mixed precision
  use_amp: false # Use automatic mixed precision
  amp_opt_level: "O1" # AMP optimization level

# Experimental Features
experimental:
  # Goal vector analysis
  analyze_goal_vectors: true # Analyze goal vector evolution
  goal_analysis_frequency: 100 # Frequency of goal vector analysis

  # Curriculum learning
  use_curriculum: false # Use curriculum learning
  curriculum_stages: [] # Curriculum stages configuration

  # Self-play
  use_self_play: false # Use self-play training
  self_play_frequency: 1000 # Self-play update frequency

  # Phase 2 features (for future implementation)
  latent_goal_space: false # Use latent goal space
  goal_discriminator: false # Use goal discriminator
  latent_goal_dim: 8 # Latent goal vector dimension

# Debugging
debug:
  profile_performance: false # Profile training performance
  save_rollouts: false # Save rollout data for debugging
  verbose_logging: false # Enable verbose logging
  check_numerics: false # Check for NaN/Inf values
  plot_gradients: false # Plot gradient statistics
